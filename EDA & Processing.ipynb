{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MoMA Collection Data Processing**\n",
    "### Table of Contents\n",
    "1. [General EDA & Initial Cleaning](#general)   \n",
    "2. [Formatting review](#formatting-review)\n",
    "3. [Standardizing Values](#standardizing-values)   \n",
    "a. [Removing punctuation & special characters](#punctuation)   \n",
    "b. [Cleaning Dates](#dates)\n",
    "4. [Extracting from Biographies](#bio-extraction)   \n",
    "a. [Extracting birthplace](#birthplace)   \n",
    "b. [Imputing nationalities](#impute-nationalities)   \n",
    "c. [Imputing Deceased Year & Creating `living` flag](#creating-living-flag)   \n",
    "5. [Data Type Corrections](#datatypes)\n",
    "6. [Title EDA](#title-eda)\n",
    "\n",
    "For the purposes of this project, the data will be limited to records with Artist Name and a single identified artist as the creator of the artwork.   \n",
    "All work done to process data for multi-artist pieces has been moved to [The Graveyard](#graveyard)   \n",
    "a. [Evaluating `nulls`](#nulls)  \n",
    "b. [Deduping within values](#deduping-within)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Corrections <a class='anchor' id='datatypes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Cleaning & EDA <a class='anchor' id='general'></a>\n",
    "#### Dropped:\n",
    "- Records missing `Artist` (1,216 records representing 0.8% of the entire catalogue)\n",
    "- Records with multiple artists listed in `Artist` (9,577 records representing 6.8% of the entire catalogue)\n",
    "  - Includes design groups/firms\n",
    "\n",
    "#### Remaining dataset used contains **131,271 artworks** from **10,875 artists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaners.moma import *\n",
    "\n",
    "original_catalogue = pd.read_csv('./MoMA Data/Artworks.csv')\n",
    "# any values without an artist listed will not be useful, setting those aside for potential investigation in the future\n",
    "missing_artists = original_catalogue[original_catalogue.Artist.isnull()==True].copy()\n",
    "artists_listed = original_catalogue.dropna(axis=0, subset=['Artist'])\n",
    "# print(len(missing_artists)/(len(original_catalogue)+len(missing_artists))), print(len(missing_artists))\n",
    "# removing works with multiple artists/groups credited\n",
    "catalogue = artists_listed[(artists_listed.Artist.str.contains(',|Associate|Architect', regex=True) == False)]\n",
    "# print((len(original_catalogue)-len(catalogue))/len(original_catalogue)), print(len(original_catalogue)-len(catalogue))\n",
    "\n",
    "movements = pd.read_csv('./WikiArt Data/movements_by_artist.csv')\n",
    "\n",
    "catalogue.drop(columns=['URL','ThumbnailURL','Circumference (cm)','Depth (cm)','Diameter (cm)','Weight (kg)','Seat Height (cm)'], inplace=True) # dropping unneeded columns\n",
    "# [print(f\"| {i} | {catalogue[i].dtype} |  |\") for i in catalogue.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content & Formatting Review <a class='anchor' id='formatting-review'></a>\n",
    "### Artist Information\n",
    "| Column | DataType | Notes |\n",
    "| --- | --- | --- |\n",
    "| ConstituentID | object | `int` |\n",
    "| Artist | object | Investigate falls non-nulls (e.g. \"Unknown\" / \"Unidentified\"...) |\n",
    "| ArtistBio | object | Extract `birthplace` & `birthyear`; create `living` flag |\n",
    "| Gender | object | Clean punctuation & dedupe |\n",
    "| Nationality | object | Clean punctuation & dedupe |\n",
    "### Artwork Information\n",
    "| Column | DataType | Notes |\n",
    "| --- | --- | --- |\n",
    "| AccessionNumber | object |  |\n",
    "| ObjectID | int64 |  |\n",
    "| Title | object | Create `untitled` flag |\n",
    "| Medium | object | Investigate overlap w/`Classification` |\n",
    "| Classification | object | Investigate overlap w/`Medium` |\n",
    "| Dimensions | object |  |\n",
    "| Height (cm) | object |  |\n",
    "| Length (cm) | object |  |\n",
    "| Width (cm) | object |  |\n",
    "| Duration (sec.) | object | `int` |\n",
    "### Dates\n",
    "| Column | DataType | Notes |\n",
    "| --- | --- | --- |\n",
    "| BeginDate | object | `int`; Clean punctuation & standardize |\n",
    "| EndDate | object | `int`; Clean punctuation & standardize |\n",
    "| Date | object | `int`; Clean punctuation & standardize` |\n",
    "### Institutional Data\n",
    "| Column | DataType | Notes |\n",
    "| --- | --- | --- |\n",
    "| CreditLine | object | Investigate potentially meaningful nulls |\n",
    "| Department | object |  |\n",
    "| DateAcquired | object | `int`; Clean punctuation & standardize |\n",
    "| Cataloged | object | `bool` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low hanging fruit\n",
    "catalogue['Cataloged'].replace({'Y':True,'N':False}, inplace=True) # converting Catalogued to boolean\n",
    "catalogue['Untitled'] = catalogue.Title.str.contains('Untitled') # creating Untitled flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Within Rows <a class=\"anchor\" id=\"standardizing-within\"></a>\n",
    "#### Cleaning Punctuation <a class=\"anchor\" id=\"punctuation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_punct(catalogue,['BeginDate','EndDate','Date'],'[^0-9\\-]')\n",
    "strip_punct(catalogue,'Nationality','[^A-Za-z0-9\\,\\-\\s]')\n",
    "strip_punct(catalogue,'ArtistBio','[\\(\\)]')\n",
    "strip_punct(catalogue,'Gender','[^A-Za-z\\-\\s]')\n",
    "\n",
    "catalogue['Gender'] = catalogue['Gender'].apply(lambda x: x.capitalize())\n",
    "catalogue.fillna('-', inplace=True) # filling nulls for easier review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Dates <a class=\"anchor\" id=\"dates\"></a>\n",
    "- Identified 3,148 or 2% of records that are missing `Date` value - see [date imputation](#date-imputation)\n",
    "- We can also capture a large share with formattings:\n",
    "  - *YYYYYYYY*\n",
    "  - *YYYY-YYYY*\n",
    "  - *YYYY-YY*\n",
    "  - later noticed and added *YYYY* which introduced an additional 2% improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131,271 total rows \n",
      "98,541 rows have dates correctly formatted\n",
      "completeness of Date 75%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adding properly formatted dates to new column\n",
    "catalogue['cleanedDate'] = 0\n",
    "clean_dates = catalogue[(catalogue.Date.str.len()==4)&(catalogue.Date.str.contains('\\D')==False)].index\n",
    "catalogue.loc[clean_dates,'cleanedDate'] = catalogue.loc[clean_dates,'Date']\n",
    "# integrity review printout\n",
    "print('{:,} total rows \\n{:,} rows have dates correctly formatted'.format(len(catalogue), len(catalogue[catalogue.Date.str.len()==4])))\n",
    "print(f'completeness of Date {len(clean_dates)/(len(catalogue)):.0%}\\n')\n",
    "\n",
    "catalogue[catalogue.Date.str.len()!=4]['Date'].value_counts()[0:2]; #missing values\n",
    "catalogue[catalogue.Date.str.len()!=4]['Date'].value_counts()[2:30]; # identifying most common, alternate Date formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YYYYYYYY & YYYYYY formatting: completeness of Date improved 6%\n",
      "YYYY-YYYY & YYYY-YY formatting: completeness of Date improved 14%\n",
      "remaining: 5%\n"
     ]
    }
   ],
   "source": [
    "# cleaning date ranges yyyyyyyy and yyyyyy\n",
    "# create index reference\n",
    "eight_digits = catalogue[((catalogue.Date.str.len()==6)|(catalogue.Date.str.len()==8))&(catalogue.Date.str.contains('\\D',regex=True)==False)].index\n",
    "# apply processing function to rows of given index\n",
    "# store formatted year in cleanedDate, remaining data in Date2 for later review\n",
    "catalogue.loc[eight_digits,'Date2'] = catalogue.loc[eight_digits,'Date'].apply(lambda x: str(x)[4:])\n",
    "catalogue.loc[eight_digits,'cleanedDate'] = catalogue.loc[eight_digits,'Date'].apply(lambda x: str(x)[0:4])\n",
    "print(f'YYYYYYYY & YYYYYY formatting: completeness of Date improved {len(eight_digits)/(len(catalogue)):.0%}')\n",
    "\n",
    "# pulling all dates with ranges yyyy-yyyy | yyyy-yy\n",
    "# create index reference\n",
    "dash_ranges = catalogue[((catalogue.Date.str.len()==7)|(catalogue.Date.str.len()==9))&(catalogue.Date.str.contains('\\d{4}\\-\\d{1,4}',regex=True))].index\n",
    "# apply processing function to rows of given index\n",
    "# store formatted year in cleanedDate, remaining data in Date2 for later review\n",
    "catalogue.loc[dash_ranges,'Date2'] = catalogue.loc[dash_ranges,'Date'].apply(lambda x: x.split('-')[1])\n",
    "catalogue.loc[dash_ranges,'cleanedDate'] = catalogue.loc[dash_ranges,'Date'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "# integrity improvements printout\n",
    "print(f'YYYY-YYYY & YYYY-YY formatting: completeness of Date improved {len(dash_ranges)/(len(catalogue)):.0%}')\n",
    "print(f'remaining: {len(catalogue[catalogue.cleanedDate==0])/len(catalogue):.000%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YYYYYYYYYY formatting: completeness of Date improved 2%\n",
      "total improvements: 21%\n"
     ]
    }
   ],
   "source": [
    "# cleaning date ranges yyyyyyyyyy\n",
    "multirange = catalogue[catalogue.Date.str.contains('\\d{9}[^\\D]', regex=True)].index\n",
    "# stashing [6:]\n",
    "catalogue.loc[multirange,'Date2'] = catalogue.loc[multirange,'Date'].apply(lambda x: str(x)[6:])\n",
    "# keeping [0:4]\n",
    "catalogue.loc[multirange,'cleanedDate'] = catalogue.loc[multirange,'Date'].apply(lambda x: str(x)[0:4])\n",
    "# discarding remainder [4:6]\n",
    "\n",
    "print(f'YYYYYYYYYY formatting: completeness of Date improved {len(multirange)/(len(catalogue)):.0%}')\n",
    "print(f'total improvements: {(len(catalogue[catalogue.cleanedDate!=0])-len(clean_dates))/(len(catalogue)):.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completeness of Date improved 6%\n",
      "total improvements: 21%\n",
      "remaining: 4%\n"
     ]
    }
   ],
   "source": [
    "daterange = catalogue[(catalogue.Date.str.len()==7)&(catalogue.Date.str.contains('-')==True)].index\n",
    "catalogue.loc[daterange,'cleanedDate'] = [i.split('-')[0] for i in catalogue.loc[daterange,'Date']]\n",
    "catalogue.loc[daterange,'Date2'] = [i.split('-')[1] for i in catalogue.loc[daterange,'Date']]\n",
    "print(f'completeness of Date improved {len(daterange)/(len(catalogue)):.0%}')\n",
    "print(f'total improvements: {(len(catalogue[catalogue.cleanedDate!=0])-len(clean_dates))/(len(catalogue)):.0%}')\n",
    "print(f'remaining: {len(catalogue[catalogue.cleanedDate==0])/len(catalogue):.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015-            41\n",
       "51877-221894     30\n",
       "1910-111912      27\n",
       "1958-641964      25\n",
       "19641965-66      25\n",
       "18-231966        25\n",
       "11970            21\n",
       "19501949-50      21\n",
       "31916            20\n",
       "19721971-1972    20\n",
       "19271925-1927    18\n",
       "-1991            17\n",
       "71925            17\n",
       "91907            16\n",
       "61966-251967     15\n",
       "17-191969        15\n",
       "1923-241925      14\n",
       "19611965-66      14\n",
       "13-191970        12\n",
       "1978-791995      11\n",
       "-1925            11\n",
       "1914-211925      10\n",
       "1999-             9\n",
       "8-131970          9\n",
       "19171907-08       9\n",
       "2-101969          9\n",
       "10-151970         9\n",
       "21-251963         9\n",
       "31915             8\n",
       "-1914             8\n",
       "29-241967         8\n",
       "19581965-66       8\n",
       "11886             8\n",
       "92000             7\n",
       "19221920-21       7\n",
       "1973-19741973     7\n",
       "19621965-66       7\n",
       "20-291967         7\n",
       "Name: Date, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalogue[(catalogue.cleanedDate==0)].Date.value_counts()[2:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining opportunities to impute Date <a class=\"anchor\" id=\"date-imputation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting From Biographies <a class=\"anchor\" id=\"bio-extraction\"></a>\n",
    "### [Extracting birthplace](#birthplace), if listed\n",
    "### [Imputing nationalities](#impute-nationalities)\n",
    "### [Creating `living` flag](#living)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Birthplace <a class=\"anchor\" id=\"birthplace\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio2ref = catalogue[catalogue.ArtistBio.str.contains(',')==True].index\n",
    "\n",
    "catalogue.loc[:,'NationalityBio'] = catalogue.loc[:,'ArtistBio'].apply(lambda x: x.split(',')[0])\n",
    "catalogue.loc[bio2ref,'Bio2'] = catalogue.loc[bio2ref,'ArtistBio'].apply(lambda x: x.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[catalogue.Bio2.str.contains('born')==True].ArtistBio.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_ref = catalogue[catalogue.ArtistBio.str.contains('born')==True].index\n",
    "\n",
    "for i in bp_ref:\n",
    "    output = list(set(re.findall('born\\s\\d{0,}\\s{0,1}([A-Za-z]+)', catalogue.loc[i,'ArtistBio'])))\n",
    "    \n",
    "    if len(output) == 1:\n",
    "        catalogue.loc[i,'Birthplace'] = output[0]\n",
    "    elif len(output) == 0:\n",
    "        catalogue.loc[i,'Birthplace'] = 'N/A'\n",
    "    else:\n",
    "        catalogue.loc[i,'Birthplace'] = [''.join(i) for i in output][0]\n",
    "        \n",
    "catalogue['Birthplace'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[' '.join(i) for i in output][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue.Birthplace.value_counts()[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "primes = [] # Set a list to catch prime values\n",
    "\n",
    "for i in range(3, 2000): \n",
    "    # All statement evaluates to true if all of the iterables satisfy the criteria\n",
    "    # If i divided by the existing primes(x) never has a remainder of 0\n",
    "    if all(i % x != 0 for x in primes):\n",
    "        # Append this number to the primes list\n",
    "        primes.append(i)\n",
    "\n",
    "sum(primes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[catalogue.Birthplace==\"['Uruguay', 'American', 'Argentine']\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[(catalogue.Nationality==None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue['Nationality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue['Bio2'].unique()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[catalogue.Birthplace.str.contains('\\[')==True].Birthplace.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Nationalities <a class=\"anchor\" id=\"impute-nationalities\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mismatches\n",
    "len(catalogue[catalogue.Nationality!=catalogue.NationalityBio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling top 10 donors, by volume\n",
    "[print('{:,} items from {}'.format(catalogue.CreditLine.value_counts()[i], i)) for i in catalogue.CreditLine.value_counts().index[0:10]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling remaining, most common formatting issues\n",
    "catalogue[catalogue.cleanedDate==0].Date.value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[(catalogue.Date==0)&(catalogue.BeginDate.str.len()==4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[(catalogue.Date==0)|(catalogue.Date==None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in catalogue.loc[ref, 'Date'].index:\n",
    "#     f = catalogue.loc[i,'Date'][:4]\n",
    "#     s = catalogue.loc[i,'Date'][4:]\n",
    "    \n",
    "#     catalogue.loc[i,'Date'] = f\n",
    "#     catalogue.loc[i,'Date2'] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Deceased Year & `living` flag <a class=\"anchor\" id=\"living\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title EDA & Imputation <a class='anchor' id='title-eda'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard\n",
    "## Turn back now!\n",
    "\n",
    "[Evaluating `nulls`](#evaluating-nulls) is no longer relevant, as the dataset was limited to single-artist artworks. Storing in graveyard for potential future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_summary = pd.DataFrame(round(catalogue.isnull().sum()/len(catalogue),2), columns=['pct'])\n",
    "null_summary = null_summary.reset_index(drop=False).rename(columns={'index':'Column'})\n",
    "# [print(f\"| {null_summary.loc[i,'Column']} | {null_summary.loc[i,'pct']} |\") for i in null_summary[null_summary.pct==0].index]\n",
    "# [print(f\"| {null_summary.loc[i,'Column']} | {null_summary.loc[i,'pct']} |\") for i in null_summary[null_summary.pct>0.1].index];\n",
    "# [print(f\"| {null_summary.loc[i,'Column']} | {null_summary.loc[i,'pct']} |\") for i in null_summary[(null_summary.pct<=0.1)&(null_summary.pct!=0)].index];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating `nulls` <a class='anchor' id='nulls'></a>\n",
    "#### Complete Columns\n",
    "- Artist (intervention)\n",
    "- Title (further explored in [Title EDA](#title-eda))\n",
    "- AccessionNumber (internal)\n",
    "- Classification (internal)\n",
    "- Department (internal)\n",
    "- Object ID (internal)\n",
    "- Cataloged (will be converted to bool)\n",
    "\n",
    "#### Looking at those columns with high frequency of nulls (>10%)...\n",
    "#### _Items to remove_\n",
    "| Column | % Null | Notes |\n",
    "| --- | --- | --- |\n",
    "| URL | 0.33 | Not needed |\n",
    "| ThumbnailURL | 0.40 | Not needed |\n",
    "| Weight (kg) | 1.0 | Not needed |\n",
    "| Seat Height (cm) | 1.0 | Not needed |\n",
    "#### _Remaining_\n",
    "| Column | % Null | Notes |\n",
    "| --- | --- | --- |\n",
    "| Circumference (cm) | 1.0 | Likely related to `Medium` |\n",
    "| Depth (cm) | 0.89 | Likely related to `Medium` |\n",
    "| Diameter (cm) | 0.99 | Likely related to `Medium` |\n",
    "| Height (cm) | 0.12 | Possible imputation w/`Dimensions` |\n",
    "| Length (cm) | 0.99 | Possible imputation w/`Dimensions` |\n",
    "| Width (cm) | 0.13 | Possible imputation w/`Dimensions` |\n",
    "| Duration (sec.) | 0.99 | Dependent on `Medium` |\n",
    "#### Looking at those columns with low frequency nulls (<10%)...\n",
    "#### _Linked to `null` Artist value_\n",
    "| Column | % Null | Notes |\n",
    "| --- | --- | --- |\n",
    "| Artist | 0.01 | Removed. Represented .008 / 0.8% of all records. |\n",
    "| ConstituentID | 0.01 | Dropped w/null artist |\n",
    "| Nationality | 0.01 | Dropped w/null artist |\n",
    "| BeginDate | 0.01 | Dropped w/null artist |\n",
    "| EndDate | 0.01 | Dropped w/null artist |\n",
    "| Gender | 0.01 | Dropped w/null artist |\n",
    "#### _Not linked to `null` Artist value_\n",
    "| Column | % Null | Notes |\n",
    "| --- | --- | --- |\n",
    "| ArtistBio | 0.03 | Will investigate further at later stage |\n",
    "| CreditLine | 0.01 | `null` may have significance/meaning (acquisition) |\n",
    "| Date | 0.01 | Will investigate overlap w/nulls in `BeginDate` and `EndDate` |\n",
    "| DateAcquired | 0.05 | Internal, will follow up as possibly useful for further analysis |\n",
    "| Dimensions | 0.06 | Possibly linked to `Medium` type |\n",
    "| Medium | 0.07 | Will investigate further at later stage |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deduping within rows <a class=\"anchor\" id=\"deduping-within\"></a>\n",
    "_Many of our features are formatted in different ways, with duplicate values within, like so:_\n",
    "- Gender: `(Male) (Male) (Male) (Male) (Male) (Male) (Male) (Male) (Male) (Female) (Male) (Male) ()`\n",
    "- Nationality: `(Spanish) (Cuban) (Spanish) (Spanish)`\n",
    "`strip_punct` handled step 1 - results:\n",
    "- Gender: `Male Female`\n",
    "- Nationality: `Spanish Cuban`\n",
    "Last step is to dedupe within values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = ['Male','Female']\n",
    "len(catalogue[(catalogue['Gender']!='Female')& (catalogue['Gender']!='Male')&(catalogue['Artist'].str.contains(','))]), len(catalogue[(catalogue['Gender']!='Female')& (catalogue['Gender']!='Male')&(catalogue['Artist'].str.contains(',')==False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[(catalogue['Gender']!='Female')& (catalogue['Gender']!='Male')&(catalogue['Artist'].str.contains(',')==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender requires deduping within row values\n",
    "catalogue['Gender'] = catalogue['Gender'].apply(lambda x: dedupe(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ''\n",
    "\n",
    "[output.join(i) for i in list(set([i.replace(')','').replace('(','') for i in re.split('\\)\\s\\(',\"(American) (American) (French)\") if len(i) > 0 ]))]\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_multi_nat(input: str) -> str:\n",
    "    return ' '.join(list(set([i.replace(')','').replace('(','').replace('\\t','') for i in re.split('\\)\\s\\(',input) if len(i) > 0 ]))).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing\n",
    "# parse_multi_nat('(American) (American) (Brazilian) (French) () (American)')\n",
    "# parse_multi_nat('(American) (American) () (American)')\n",
    "parse_multi_nat('(German) (Swedish) (German)\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_nationality = catalogue[catalogue.Nationality.str.contains('\\) ')].index\n",
    "catalogue.loc[multi_nationality,'cleanedNationality'] = catalogue.loc[multi_nationality,'Nationality'].apply(lambda x: parse_multi_nat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_nats = catalogue[catalogue.cleanedNationality.isnull()].index\n",
    "catalogue.loc[clean_nats,'cleanedNationality'] = catalogue.loc[clean_nats,'Nationality']\n",
    "# catalogue.loc[:,'cleanedNationality'] = catalogue.loc[:,'cleanedNationality'].str.replace(' Nationality unkown ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue.cleanedNationality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # improved method\n",
    "# #processing dates formatted YYYYYYYY\n",
    "# nodash = catalogue[(catalogue.Date.str.len()==8)&(catalogue.Date.str.contains('-')==False)].index\n",
    "# catalogue.loc[nodash,'cleanedDate'] = [int(i[0:4]) for i in catalogue.loc[nodash,'Date']]\n",
    "# catalogue.loc[nodash,'Date2'] = [int(i[4:]) for i in catalogue.loc[nodash,'Date']]\n",
    "\n",
    "# print(f'completeness of Date improved {len(nodash)/(len(catalogue)):.0%}')\n",
    "# print(f'total improvements: {(len(catalogue[catalogue.cleanedDate!=0])-len(clean_dates))/(len(catalogue)):.0%}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
