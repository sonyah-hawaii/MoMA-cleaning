{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MoMA Collection Data Processing**\n",
    "### Table of Contents\n",
    "1. [General EDA & Initial Cleaning](#general)   \n",
    "2. [Formatting review](#formatting-review)\n",
    "3. [Standardizing Values](#standardizing-values)   \n",
    "a. [Removing punctuation & special characters](#punctuation)   \n",
    "b. [Cleaning Dates](#dates)\n",
    "4. [Extracting from Biographies](#bio-extraction)   \n",
    "a. [Extracting birthplace](#birthplace)   \n",
    "b. [Imputing nationalities](#impute-nationalities)   \n",
    "c. [Imputing Deceased Year & Creating `living` flag](#creating-living-flag)   \n",
    "5. [Data Type Corrections](#datatypes)\n",
    "6. [Title EDA](#title-eda)\n",
    "\n",
    "For the purposes of this project, the data will be limited to records with a singular artist listed as the creator of the artwork.   \n",
    "All work done to process data for multi-artist pieces has been moved to [The Graveyard](#graveyard)   \n",
    "a. [Evaluating `nulls`](#nulls)  \n",
    "b. [Deduping within values](#deduping-within)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Corrections <a class='anchor' id='datatypes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Cleaning & EDA <a class='anchor' id='general'></a>\n",
    "#### Dropped:\n",
    "- Records missing `Artist` (1,216 records representing 0.8% of the entire catalogue)\n",
    "- Records with multiple artists listed in `Artist` (9,577 records representing 6.8% of the entire catalogue)\n",
    "  - Includes design groups/firms\n",
    "\n",
    "#### Remaining dataset used contains **131,271 artworks** from **10,875 artists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_moma import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "original_catalogue = pd.read_csv('./data/MoMA data/Artworks.csv')\n",
    "# any values without an artist listed will not be useful, setting those aside for potential investigation in the future\n",
    "missing_artists = original_catalogue[original_catalogue.Artist.isnull()==True].copy()\n",
    "artists_listed = original_catalogue.dropna(axis=0, subset=['Artist']).copy()\n",
    "# print(len(missing_artists)/(len(original_catalogue)+len(missing_artists))), print(len(missing_artists))\n",
    "# removing works with multiple artists/groups credited\n",
    "catalogue = artists_listed[(artists_listed.Artist.str.contains(',|Associate|Architect', regex=True) == False)].copy()\n",
    "# print((len(original_catalogue)-len(catalogue))/len(original_catalogue)), print(len(original_catalogue)-len(catalogue))\n",
    "\n",
    "movements = pd.read_csv('./data/WikiArt Data/movements_by_artist.csv')\n",
    "\n",
    "catalogue.drop(columns=['URL','ThumbnailURL','Circumference (cm)','Depth (cm)','Diameter (cm)','Weight (kg)','Seat Height (cm)'], inplace=True) # dropping unneeded columns\n",
    "# [print(f\"| {i} | {catalogue[i].dtype} |  |\") for i in catalogue.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content & Formatting Review <a class='anchor' id='formatting-review'></a>\n",
    "### Artist Information\n",
    "| Column | DataType | Notes |\n",
    "| --- | --- | --- |\n",
    "| ConstituentID | object | `int` |\n",
    "| Artist | object | Investigate falls non-nulls (e.g. \"Unknown\" / \"Unidentified\"...) |\n",
    "| ArtistBio | object | Extract `birthplace` & `birthyear`; create `living` flag |\n",
    "| Gender | object | Clean punctuation & dedupe |\n",
    "| Nationality | object | Clean punctuation & dedupe |\n",
    "### Artwork Information\n",
    "| Column | DataType | Notes |\n",
    "| --- | --- | --- |\n",
    "| AccessionNumber | object |  |\n",
    "| ObjectID | int64 |  |\n",
    "| Title | object | Create `untitled` flag |\n",
    "| Medium | object | Investigate overlap w/`Classification` |\n",
    "| Classification | object | Investigate overlap w/`Medium` |\n",
    "| Dimensions | object |  |\n",
    "| Height (cm) | object |  |\n",
    "| Length (cm) | object |  |\n",
    "| Width (cm) | object |  |\n",
    "| Duration (sec.) | object | `int` |\n",
    "### Dates\n",
    "| Column | DataType | Notes |\n",
    "| --- | --- | --- |\n",
    "| BeginDate | object | `int`; Clean punctuation & standardize |\n",
    "| EndDate | object | `int`; Clean punctuation & standardize |\n",
    "| Date | object | `int`; Clean punctuation & standardize` |\n",
    "### Institutional Data\n",
    "| Column | DataType | Notes |\n",
    "| --- | --- | --- |\n",
    "| CreditLine | object | Investigate potentially meaningful nulls |\n",
    "| Department | object |  |\n",
    "| DateAcquired | object | `int`; Clean punctuation & standardize |\n",
    "| Cataloged | object | `bool` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low hanging fruit\n",
    "catalogue['Cataloged'].replace({'Y':True,'N':False}, inplace=True) # converting Catalogued to boolean\n",
    "catalogue['Untitled'] = catalogue['Title'].str.contains('Untitled') # creating Untitled flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Within Rows <a class=\"anchor\" id=\"standardizing-within\"></a>\n",
    "#### Cleaning Punctuation <a class=\"anchor\" id=\"punctuation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = {\n",
    "#     'moma': moma,\n",
    "#     'wikiart': wa,\n",
    "#     'agp': agp\n",
    "# }\n",
    "\n",
    "punctuation = [\n",
    "    {\n",
    "        'columns': ['BeginDate','EndDate','Date'],\n",
    "        'pattern': '[^0-9\\-]'\n",
    "    },\n",
    "    {\n",
    "        'columns': 'Nationality',\n",
    "        'pattern': '[^A-Za-z0-9\\,\\-\\s]'\n",
    "    },\n",
    "    {\n",
    "        'columns': 'ArtistBio',\n",
    "        'pattern': '[\\(\\)]'\n",
    "    },\n",
    "    {\n",
    "        'columns': 'Gender',\n",
    "        'pattern': '[^A-Za-z\\-\\s]'\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "for item in punctuation:\n",
    "    strip_punct(catalogue, item['columns'], item['pattern'])\n",
    "    \n",
    "catalogue['Gender'] = catalogue['Gender'].apply(lambda x: x.capitalize())\n",
    "catalogue.fillna('-', inplace=True) # filling nulls for easier review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Dates <a class=\"anchor\" id=\"dates\"></a>\n",
    "75% of `Date` records were complete & correctly formatted (98,541 of 131,271 records).   \n",
    "Achieved 23% improvement (30,269 records) with `format_date` function.   \n",
    "     \n",
    "3,148 or 2% of records are missing `Date` value **_see_**: [date imputation](#date-imputation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue['date_cleaned'] = catalogue['Date'].apply(lambda x: format_date(x)[0]) # processing & overwriting date column\n",
    "catalogue['date2'] = catalogue['Date'].apply(lambda x: format_date(x)[1]) # storing additional data in secondary field for later review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original code & notes for improvement measurements\n",
    "# # clean_dates = catalogue[(catalogue.Date.str.len()==4)&(catalogue.Date.str.contains('\\D')==False)].index\n",
    "# catalogue.loc[clean_dates,'cleanedDate'] = catalogue.loc[clean_dates,'Date']\n",
    "# integrity review printout\n",
    "# print('{:,} total rows \\n{:,} rows have dates correctly formatted'.format(len(catalogue), len(catalogue[catalogue.Date.str.len()==4])))\n",
    "# print(f'completeness of Date {len(clean_dates)/(len(catalogue)):.0%}\\n')\n",
    "\n",
    "# catalogue[catalogue.Date.str.len()!=4]['Date'].value_counts()[0:2]; #missing values\n",
    "# catalogue[catalogue.Date.str.len()!=4]['Date'].value_counts()[2:30]; # identifying most common, alternate Date formatting\n",
    "\n",
    "# cleaning date ranges yyyyyyyy and yyyyyy\n",
    "# create index reference\n",
    "# eight_digits = catalogue[((catalogue.Date.str.len()==6)|(catalogue.Date.str.len()==8))&(catalogue.Date.str.contains('\\D',regex=True)==False)].index\n",
    "# apply processing function to rows of given index\n",
    "# store formatted year in cleanedDate, remaining data in Date2 for later review\n",
    "# catalogue.loc[eight_digits,'Date2'] = catalogue.loc[eight_digits,'Date'].apply(lambda x: str(x)[4:])\n",
    "# catalogue.loc[eight_digits,'cleanedDate'] = catalogue.loc[eight_digits,'Date'].apply(lambda x: str(x)[0:4])\n",
    "# print(f'YYYYYYYY & YYYYYY formatting: completeness of Date improved {len(eight_digits)/(len(catalogue)):.0%}')\n",
    "\n",
    "# pulling all dates with ranges yyyy-yyyy | yyyy-yy\n",
    "# create index reference\n",
    "# dash_ranges = catalogue[((catalogue.Date.str.len()==7)|(catalogue.Date.str.len()==9))&(catalogue.Date.str.contains('\\d{4}\\-\\d{1,4}',regex=True))].index\n",
    "# apply processing function to rows of given index\n",
    "# store formatted year in cleanedDate, remaining data in Date2 for later review\n",
    "# catalogue.loc[dash_ranges,'Date2'] = catalogue.loc[dash_ranges,'Date'].apply(lambda x: x.split('-')[1])\n",
    "# catalogue.loc[dash_ranges,'cleanedDate'] = catalogue.loc[dash_ranges,'Date'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "# integrity improvements printout\n",
    "# print(f'YYYY-YYYY & YYYY-YY formatting: completeness of Date improved {len(dash_ranges)/(len(catalogue)):.0%}')\n",
    "# print(f'remaining: {len(catalogue[catalogue.cleanedDate==0])/len(catalogue):.000%}')\n",
    "\n",
    "# cleaning date ranges yyyyyyyyyy\n",
    "# multirange = catalogue[catalogue.Date.str.contains('\\d{9}[^\\D]', regex=True)].index\n",
    "# stashing [6:]\n",
    "# catalogue.loc[multirange,'Date2'] = catalogue.loc[multirange,'Date'].apply(lambda x: str(x)[6:])\n",
    "# keeping [0:4]\n",
    "# catalogue.loc[multirange,'cleanedDate'] = catalogue.loc[multirange,'Date'].apply(lambda x: str(x)[0:4])\n",
    "# discarding remainder [4:6]\n",
    "\n",
    "# print(f'YYYYYYYYYY formatting: completeness of Date improved {len(multirange)/(len(catalogue)):.0%}')\n",
    "# print(f'total improvements: {(len(catalogue[catalogue.cleanedDate!=0])-len(clean_dates))/(len(catalogue)):.0%}')\n",
    "# sum(catalogue[catalogue['Date_test']==0]['Date'].value_counts())/len(catalogue)\n",
    "# 98_541/len(catalogue)\n",
    "# (len(catalogue)-(sum(catalogue[catalogue['Date_test']==0]['Date'].value_counts())+98541))\n",
    "# daterange = catalogue[(catalogue.Date.str.len()==7)&(catalogue.Date.str.contains('-')==True)].index\n",
    "\n",
    "# catalogue.loc[daterange,'cleanedDate'] = [i.split('-')[0] for i in catalogue.loc[daterange,'Date']]\n",
    "# catalogue.loc[daterange,'Date2'] = [i.split('-')[1] for i in catalogue.loc[daterange,'Date']]\n",
    "# print(f'completeness of Date improved {len(daterange)/(len(catalogue)):.0%}')\n",
    "# print(f'total improvements: {(len(catalogue[catalogue.cleanedDate!=0])-len(clean_dates))/(len(catalogue)):.0%}')\n",
    "# print(f'remaining: {len(catalogue[catalogue.cleanedDate==0])/len(catalogue):.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(set([i for i in n if i != '']))[1:-1].replace('\\'','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining opportunities to impute Date <a class=\"anchor\" id=\"date-imputation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting From Biographies <a class=\"anchor\" id=\"bio-extraction\"></a>\n",
    "### [Extracting birthplace](#birthplace), if listed\n",
    "### [Imputing nationalities](#impute-nationalities)\n",
    "### [Creating `living` flag](#living)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Birthplace <a class=\"anchor\" id=\"birthplace\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio2ref = catalogue[catalogue.ArtistBio.str.contains(',')==True].index\n",
    "\n",
    "catalogue.loc[:,'NationalityBio'] = catalogue.loc[:,'ArtistBio'].apply(lambda x: x.split(',')[0])\n",
    "catalogue.loc[bio2ref,'Bio2'] = catalogue.loc[bio2ref,'ArtistBio'].apply(lambda x: x.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "American, born France. 1911–2010                3336\n",
       "American, born Germany. 1886–1969               2657\n",
       "American, born 1934                             1534\n",
       "French, born Belarus. 1887–1985                 1161\n",
       "American, born Lithuania. 1931–1978              821\n",
       "                                                ... \n",
       "American, born England. 1906–1994                  1\n",
       "French, born Romania 1922                          1\n",
       "Brazilian, born Poland. 1921–2017                  1\n",
       "British, born British Guiana now Guyana 1934       1\n",
       "Malian, born 1953                                  1\n",
       "Name: ArtistBio, Length: 2057, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalogue[catalogue.Bio2.str.contains('born')==True].ArtistBio.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     catalogue\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBirthplace\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     catalogue\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBirthplace\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     catalogue\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBirthplace\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m output][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sonya\\miniconda3\\envs\\work_env\\lib\\site-packages\\pandas\\core\\indexing.py:723\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    722\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 723\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonya\\miniconda3\\envs\\work_env\\lib\\site-packages\\pandas\\core\\indexing.py:1730\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1729\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1730\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\sonya\\miniconda3\\envs\\work_env\\lib\\site-packages\\pandas\\core\\indexing.py:1817\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m \n\u001b[0;32m   1815\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m ilocs:\n\u001b[1;32m-> 1817\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonya\\miniconda3\\envs\\work_env\\lib\\site-packages\\pandas\\core\\indexing.py:1924\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   1921\u001b[0m     ser\u001b[38;5;241m.\u001b[39m_maybe_update_cacher(clear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# reset the sliced object if unique\u001b[39;00m\n\u001b[1;32m-> 1924\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iset_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonya\\miniconda3\\envs\\work_env\\lib\\site-packages\\pandas\\core\\frame.py:3766\u001b[0m, in \u001b[0;36mDataFrame._iset_item\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   3764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iset_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc: \u001b[38;5;28mint\u001b[39m, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3765\u001b[0m     arraylike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m-> 3766\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iset_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marraylike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3768\u001b[0m     \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n\u001b[0;32m   3769\u001b[0m     \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m     \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n\u001b[0;32m   3771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\sonya\\miniconda3\\envs\\work_env\\lib\\site-packages\\pandas\\core\\frame.py:3746\u001b[0m, in \u001b[0;36mDataFrame._iset_item_mgr\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   3744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iset_item_mgr\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3745\u001b[0m     \u001b[38;5;66;03m# when called from _set_item_mgr loc can be anything returned from get_loc\u001b[39;00m\n\u001b[1;32m-> 3746\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3747\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\sonya\\miniconda3\\envs\\work_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1068\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     loc \u001b[38;5;241m=\u001b[39m [loc]  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;66;03m# Accessing public blknos ensures the public versions are initialized\u001b[39;00m\n\u001b[1;32m-> 1068\u001b[0m blknos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblknos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1069\u001b[0m blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs[loc]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m   1071\u001b[0m unfit_mgr_locs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bp_ref = catalogue[catalogue.ArtistBio.str.contains('born')==True].index\n",
    "\n",
    "for i in bp_ref:\n",
    "    output = list(set(re.findall('born\\s\\d{0,}\\s{0,1}([A-Za-z]+)', catalogue.loc[i,'ArtistBio'])))\n",
    "    \n",
    "    if len(output) == 1:\n",
    "        catalogue.loc[i,'Birthplace'] = output[0]\n",
    "    elif len(output) == 0:\n",
    "        catalogue.loc[i,'Birthplace'] = 'N/A'\n",
    "    else:\n",
    "        catalogue.loc[i,'Birthplace'] = [''.join(i) for i in output][0]\n",
    "        \n",
    "catalogue['Birthplace'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[' '.join(i) for i in output][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue.Birthplace.value_counts()[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "primes = [] # Set a list to catch prime values\n",
    "\n",
    "for i in range(3, 2000): \n",
    "    # All statement evaluates to true if all of the iterables satisfy the criteria\n",
    "    # If i divided by the existing primes(x) never has a remainder of 0\n",
    "    if all(i % x != 0 for x in primes):\n",
    "        # Append this number to the primes list\n",
    "        primes.append(i)\n",
    "\n",
    "sum(primes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[catalogue.Birthplace==\"['Uruguay', 'American', 'Argentine']\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[(catalogue.Nationality==None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue['Nationality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue['Bio2'].unique()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[catalogue.Birthplace.str.contains('\\[')==True].Birthplace.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Nationalities <a class=\"anchor\" id=\"impute-nationalities\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mismatches\n",
    "len(catalogue[catalogue.Nationality!=catalogue.NationalityBio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling top 10 donors, by volume\n",
    "[print('{:,} items from {}'.format(catalogue.CreditLine.value_counts()[i], i)) for i in catalogue.CreditLine.value_counts().index[0:10]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling remaining, most common formatting issues\n",
    "catalogue[catalogue.cleanedDate==0].Date.value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[(catalogue.Date==0)&(catalogue.BeginDate.str.len()==4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[(catalogue.Date==0)|(catalogue.Date==None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in catalogue.loc[ref, 'Date'].index:\n",
    "#     f = catalogue.loc[i,'Date'][:4]\n",
    "#     s = catalogue.loc[i,'Date'][4:]\n",
    "    \n",
    "#     catalogue.loc[i,'Date'] = f\n",
    "#     catalogue.loc[i,'Date2'] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Deceased Year & `living` flag <a class=\"anchor\" id=\"living\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title EDA & Imputation <a class='anchor' id='title-eda'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard\n",
    "## Turn back now!\n",
    "\n",
    "[Evaluating `nulls`](#evaluating-nulls) is no longer relevant, as the dataset was limited to single-artist artworks. Storing in graveyard for potential future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_summary = pd.DataFrame(round(catalogue.isnull().sum()/len(catalogue),2), columns=['pct'])\n",
    "null_summary = null_summary.reset_index(drop=False).rename(columns={'index':'Column'})\n",
    "# [print(f\"| {null_summary.loc[i,'Column']} | {null_summary.loc[i,'pct']} |\") for i in null_summary[null_summary.pct==0].index]\n",
    "# [print(f\"| {null_summary.loc[i,'Column']} | {null_summary.loc[i,'pct']} |\") for i in null_summary[null_summary.pct>0.1].index];\n",
    "# [print(f\"| {null_summary.loc[i,'Column']} | {null_summary.loc[i,'pct']} |\") for i in null_summary[(null_summary.pct<=0.1)&(null_summary.pct!=0)].index];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating `nulls` <a class='anchor' id='nulls'></a>\n",
    "#### Complete Columns\n",
    "- Artist (intervention)\n",
    "- Title (further explored in [Title EDA](#title-eda))\n",
    "- AccessionNumber (internal)\n",
    "- Classification (internal)\n",
    "- Department (internal)\n",
    "- Object ID (internal)\n",
    "- Cataloged (will be converted to bool)\n",
    "\n",
    "#### Looking at those columns with high frequency of nulls (>10%)...\n",
    "#### _Items to remove_\n",
    "| Column | % Null | Notes |\n",
    "| --- | --- | --- |\n",
    "| URL | 0.33 | Not needed |\n",
    "| ThumbnailURL | 0.40 | Not needed |\n",
    "| Weight (kg) | 1.0 | Not needed |\n",
    "| Seat Height (cm) | 1.0 | Not needed |\n",
    "#### _Remaining_\n",
    "| Column | % Null | Notes |\n",
    "| --- | --- | --- |\n",
    "| Circumference (cm) | 1.0 | Likely related to `Medium` |\n",
    "| Depth (cm) | 0.89 | Likely related to `Medium` |\n",
    "| Diameter (cm) | 0.99 | Likely related to `Medium` |\n",
    "| Height (cm) | 0.12 | Possible imputation w/`Dimensions` |\n",
    "| Length (cm) | 0.99 | Possible imputation w/`Dimensions` |\n",
    "| Width (cm) | 0.13 | Possible imputation w/`Dimensions` |\n",
    "| Duration (sec.) | 0.99 | Dependent on `Medium` |\n",
    "#### Looking at those columns with low frequency nulls (<10%)...\n",
    "#### _Linked to `null` Artist value_\n",
    "| Column | % Null | Notes |\n",
    "| --- | --- | --- |\n",
    "| Artist | 0.01 | Removed. Represented .008 / 0.8% of all records. |\n",
    "| ConstituentID | 0.01 | Dropped w/null artist |\n",
    "| Nationality | 0.01 | Dropped w/null artist |\n",
    "| BeginDate | 0.01 | Dropped w/null artist |\n",
    "| EndDate | 0.01 | Dropped w/null artist |\n",
    "| Gender | 0.01 | Dropped w/null artist |\n",
    "#### _Not linked to `null` Artist value_\n",
    "| Column | % Null | Notes |\n",
    "| --- | --- | --- |\n",
    "| ArtistBio | 0.03 | Will investigate further at later stage |\n",
    "| CreditLine | 0.01 | `null` may have significance/meaning (acquisition) |\n",
    "| Date | 0.01 | Will investigate overlap w/nulls in `BeginDate` and `EndDate` |\n",
    "| DateAcquired | 0.05 | Internal, will follow up as possibly useful for further analysis |\n",
    "| Dimensions | 0.06 | Possibly linked to `Medium` type |\n",
    "| Medium | 0.07 | Will investigate further at later stage |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deduping within rows <a class=\"anchor\" id=\"deduping-within\"></a>\n",
    "_Many of our features are formatted in different ways, with duplicate values within, like so:_\n",
    "- Gender: `(Male) (Male) (Male) (Male) (Male) (Male) (Male) (Male) (Male) (Female) (Male) (Male) ()`\n",
    "- Nationality: `(Spanish) (Cuban) (Spanish) (Spanish)`\n",
    "`strip_punct` handled step 1 - results:\n",
    "- Gender: `Male Female`\n",
    "- Nationality: `Spanish Cuban`\n",
    "Last step is to dedupe within values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe(input: str) -> str:\n",
    "    '''\n",
    "    Takes in a string and processes it to return unique gender(s).\n",
    "    '''\n",
    "    n = [i.capitalize() for i in input.strip().split(' ')]\n",
    "    if len(set(n)) == 1:\n",
    "        if n[0] is None or n[0] == '':\n",
    "            return 'N/A'\n",
    "        return list(set(n))[0]\n",
    "    else:\n",
    "        return str(set([i for i in n if i != '']))[1:-1].replace('\\'','')\n",
    "\n",
    "standard = ['Male','Female']\n",
    "len(catalogue[(catalogue['Gender']!='Female')& (catalogue['Gender']!='Male')&(catalogue['Artist'].str.contains(','))]), len(catalogue[(catalogue['Gender']!='Female')& (catalogue['Gender']!='Male')&(catalogue['Artist'].str.contains(',')==False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue[(catalogue['Gender']!='Female')& (catalogue['Gender']!='Male')&(catalogue['Artist'].str.contains(',')==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender requires deduping within row values\n",
    "catalogue['Gender'] = catalogue['Gender'].apply(lambda x: dedupe(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ''\n",
    "\n",
    "[output.join(i) for i in list(set([i.replace(')','').replace('(','') for i in re.split('\\)\\s\\(',\"(American) (American) (French)\") if len(i) > 0 ]))]\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_multi_nat(input: str) -> str:\n",
    "    return ' '.join(list(set([i.replace(')','').replace('(','').replace('\\t','') for i in re.split('\\)\\s\\(',input) if len(i) > 0 ]))).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing\n",
    "# parse_multi_nat('(American) (American) (Brazilian) (French) () (American)')\n",
    "# parse_multi_nat('(American) (American) () (American)')\n",
    "parse_multi_nat('(German) (Swedish) (German)\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_nationality = catalogue[catalogue.Nationality.str.contains('\\) ')].index\n",
    "catalogue.loc[multi_nationality,'cleanedNationality'] = catalogue.loc[multi_nationality,'Nationality'].apply(lambda x: parse_multi_nat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_nats = catalogue[catalogue.cleanedNationality.isnull()].index\n",
    "catalogue.loc[clean_nats,'cleanedNationality'] = catalogue.loc[clean_nats,'Nationality']\n",
    "# catalogue.loc[:,'cleanedNationality'] = catalogue.loc[:,'cleanedNationality'].str.replace(' Nationality unkown ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue.cleanedNationality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # improved method\n",
    "# #processing dates formatted YYYYYYYY\n",
    "# nodash = catalogue[(catalogue.Date.str.len()==8)&(catalogue.Date.str.contains('-')==False)].index\n",
    "# catalogue.loc[nodash,'cleanedDate'] = [int(i[0:4]) for i in catalogue.loc[nodash,'Date']]\n",
    "# catalogue.loc[nodash,'Date2'] = [int(i[4:]) for i in catalogue.loc[nodash,'Date']]\n",
    "\n",
    "# print(f'completeness of Date improved {len(nodash)/(len(catalogue)):.0%}')\n",
    "# print(f'total improvements: {(len(catalogue[catalogue.cleanedDate!=0])-len(clean_dates))/(len(catalogue)):.0%}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
